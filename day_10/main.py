import os
import asyncio
from typing import List, Dict, Any
import chainlit as cl
from chainlit.input_widget import TextInput, Select, Slider
from providers.yandexcloud import YandexCloudProvider
from dotenv import load_dotenv
import memory

# Load environment variables
load_dotenv()

# Initialize the YandexCloud provider
provider = YandexCloudProvider()


async def display_history(view_mode: str):
    """Display conversation history based on view mode"""
    if view_mode == "–ü–æ–ª–Ω–∞—è –∏—Å—Ç–æ—Ä–∏—è":
        messages = memory.get_full_history()
    else:
        messages = memory.get_ai_history()

    if not messages:
        await cl.Message(content="üìù –ò—Å—Ç–æ—Ä–∏—è —Å–æ–æ–±—â–µ–Ω–∏–π –ø—É—Å—Ç–∞.").send()
        return

    history_text = "üìö **–ò—Å—Ç–æ—Ä–∏—è —Å–æ–æ–±—â–µ–Ω–∏–π:**\n\n"

    for i, msg in enumerate(messages, 1):
        role_emoji = {"user": "üë§", "assistant": "ü§ñ", "system": "‚öôÔ∏è"}.get(
            msg["role"], "‚ùì"
        )

        # Add summary indicator for full history view
        summary_indicator = (
            " üìã *—Å–∞–º–º–∞—Ä–∏*"
            if view_mode == "–ü–æ–ª–Ω–∞—è –∏—Å—Ç–æ—Ä–∏—è" and msg.get("is_summary", False)
            else ""
        )

        history_text += f"{i}. {role_emoji} **{msg['role'].title()}**{summary_indicator}:\n{msg['content']}\n\n"

    # Split into chunks if too long for Chainlit
    max_chunk_size = 4000
    if len(history_text) <= max_chunk_size:
        await cl.Message(content=history_text).send()
    else:
        # Split into chunks
        chunks = [
            history_text[i : i + max_chunk_size]
            for i in range(0, len(history_text), max_chunk_size)
        ]
        for i, chunk in enumerate(chunks):
            await cl.Message(
                content=f"**–ß–∞—Å—Ç—å {i + 1}/{len(chunks)}**\n\n{chunk}"
            ).send()


@cl.on_chat_start
async def on_chat_start():
    """Initialize the chat session"""
    # Set initial settings
    settings = await cl.ChatSettings(
        [
            TextInput(
                id="temperature",
                label="–¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞",
                initial="0.7",
                description="–ö–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É–µ—Ç —Å–ª—É—á–∞–π–Ω–æ—Å—Ç—å –æ—Ç–≤–µ—Ç–æ–≤ (0.0-1.0)",
            ),
            Select(
                id="model",
                label="–ú–æ–¥–µ–ª—å",
                values=["yandexgpt-lite/latest", "yandexgpt/latest"],
                initial="yandexgpt-lite/latest",
            ),
            Select(
                id="history_view",
                label="–†–µ–∂–∏–º –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ –∏—Å—Ç–æ—Ä–∏–∏",
                values=["–ü–æ–ª–Ω–∞—è –∏—Å—Ç–æ—Ä–∏—è", "–ö–∞–∫ –¥–ª—è AI (—Å —Å–∞–º–º–∞—Ä–∏)"],
                initial="–ü–æ–ª–Ω–∞—è –∏—Å—Ç–æ—Ä–∏—è",
            ),
        ]
    ).send()

    message_count = memory.get_message_count()

    if message_count > 0:
        await display_history("–ü–æ–ª–Ω–∞—è –∏—Å—Ç–æ—Ä–∏—è")
        await cl.Message(
            content=f"üìÇ –í–æ–∑–æ–±–Ω–æ–≤–ª—ë–Ω –¥–∏–∞–ª–æ–≥ —Å {message_count} —Å–æ–æ–±—â–µ–Ω–∏—è–º–∏."
        ).send()
    else:
        # Send welcome message
        await cl.Message(
            content="üëã –ü—Ä–∏–≤–µ—Ç! –Ø –≥–æ—Ç–æ–≤ –∫ –æ–±—â–µ–Ω–∏—é. –ß–µ–º –º–æ–≥—É –ø–æ–º–æ—á—å?"
        ).send()


async def summarize_conversation(history: List[Dict[str, str]]) -> str:
    """Summarize the recent conversation history and return a summary message"""
    # Create a prompt for summarization
    summarize_prompt = {
        "role": "user",
        "content": "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø—Ä–µ–¥–æ—Å—Ç–∞–≤—å—Ç–µ –∫—Ä–∞—Ç–∫–æ–µ —Ä–µ–∑—é–º–µ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π –≤ –Ω–∞—à–µ–º —Ä–∞–∑–≥–æ–≤–æ—Ä–µ. –°–æ—Å—Ä–µ–¥–æ—Ç–æ—á—å—Ç–µ—Å—å –Ω–∞ –æ—Å–Ω–æ–≤–Ω—ã—Ö –æ–±—Å—É–∂–¥—ë–Ω–Ω—ã—Ö —Ç–µ–º–∞—Ö, –ø—Ä–∏–Ω—è—Ç—ã—Ö –∫–ª—é—á–µ–≤—ã—Ö —Ä–µ—à–µ–Ω–∏—è—Ö –∏ –ª—é–±–æ–π –≤–∞–∂–Ω–æ–π –æ–±–º–µ–Ω—ë–Ω–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏. –°–¥–µ–ª–∞–π—Ç–µ —ç—Ç–æ –∫—Ä–∞—Ç–∫–æ, –Ω–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω–æ.",
    }

    # Add the summarize prompt to the history
    messages_for_summary = history + [summarize_prompt]

    # Get settings from environment or use defaults
    temperature = float(os.getenv("YANDEXCLOUD_TEMPERATURE", "0.7"))
    model = os.getenv("YANDEXCLOUD_MODEL", "yandexgpt-lite/latest")

    try:
        # Call the YandexCloud API to get a summary
        response = await provider.completions(
            messages=messages_for_summary, temperature=temperature, model=model
        )

        if response and response.text:
            return response.text
        else:
            return "–°–∞–º–º–∞—Ä–∏ –±–µ—Å–µ–¥—ã –Ω–µ —É–¥–∞–ª–æ—Å—å —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å."
    except Exception as e:
        return f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å–∞–º–º–∞—Ä–∏: {str(e)}"


@cl.on_message
async def on_message(message: cl.Message):
    """Handle incoming user messages"""

    # Get message content
    user_content = message.content

    # Handle special commands for history display
    if user_content.strip() in ["/history", "/–∏—Å—Ç–æ—Ä–∏—è"]:
        await display_history("–ü–æ–ª–Ω–∞—è –∏—Å—Ç–æ—Ä–∏—è")
        return

    if user_content.strip() in ["/ai_history", "/ai_–∏—Å—Ç–æ—Ä–∏—è"]:
        await display_history("–ö–∞–∫ –¥–ª—è AI (—Å —Å–∞–º–º–∞—Ä–∏)")
        return

    # Store user message in database
    memory.add_message("user", user_content)

    # Create a placeholder for the AI response
    response_placeholder = cl.Message(content="")
    await response_placeholder.send()

    # Get settings from environment or use defaults
    temperature = float(os.getenv("YANDEXCLOUD_TEMPERATURE", "0.7"))
    model = os.getenv("YANDEXCLOUD_MODEL", "yandexgpt-lite/latest")

    # Show typing indicator
    await response_placeholder.stream_token("ü§î –î—É–º–∞—é...")

    # Get conversation history from database (AI gets summarized context)
    conversation_history = memory.get_ai_history()

    # Call the YandexCloud API
    try:
        response = await provider.completions(
            messages=conversation_history, temperature=temperature, model=model
        )

        if response and response.text:
            # Clear the thinking indicator and update with actual response
            response_placeholder.content = ""

            # Stream the response token by token (simulated)
            ai_response = response.text

            # Update the message with the full response
            await response_placeholder.stream_token(ai_response)

            # Store assistant response in database
            memory.add_message("assistant", ai_response)

            # Check if we need to summarize the conversation (every 10 messages since last summary)
            messages_since_summary = memory.get_messages_since_last_summary_count()
            if messages_since_summary >= 10:
                # Notify user that we're summarizing
                await cl.Message(
                    content="üìù –°–æ–∑–¥–∞—é —Å–∞–º–º–∞—Ä–∏ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞..."
                ).send()

                # Get messages since last summary for summarization
                messages_since_summary = memory.get_messages_since_summary()

                # Generate summary
                summary = await summarize_conversation(
                    [
                        {"role": msg["role"], "content": msg["content"]}
                        for msg in messages_since_summary
                    ]
                )

                # Add summary as system message (preserving full history)
                summary_content = f"–ö—Ä–∞—Ç–∫–æ–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π: {summary}"
                memory.add_summary(summary_content)

                # Notify user that summarization is complete
                await cl.Message(
                    content=f"‚úÖ –°–æ–∑–¥–∞–Ω–æ —Å–∞–º–º–∞—Ä–∏ –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞.\n{summary}"
                ).send()

            # Update the message with final content
            await response_placeholder.update()

        else:
            # Clear the thinking indicator and show error message
            response_placeholder.content = ""
            error_message = "‚ùå –ò–∑–≤–∏–Ω–∏—Ç–µ, –º–Ω–µ –Ω–µ —É–¥–∞–ª–æ—Å—å —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å –æ—Ç–≤–µ—Ç. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–æ–≤–∞."
            await response_placeholder.stream_token(error_message)
            await response_placeholder.update()

    except Exception as e:
        # Clear the thinking indicator and show error message
        response_placeholder.content = ""
        error_message = f"‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {str(e)}"
        await response_placeholder.stream_token(error_message)
        await response_placeholder.update()


@cl.on_settings_update
async def on_settings_update(settings: Dict[str, Any]):
    """Handle settings updates"""
    temperature = settings.get("temperature", 0.7)
    model = settings.get("model", "yandexgpt-lite/latest")
    history_view = settings.get("history_view", "–ü–æ–ª–Ω–∞—è –∏—Å—Ç–æ—Ä–∏—è")

    # Display history based on the selected view mode
    await display_history(history_view)

    await cl.Message(
        content=f"‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –æ–±–Ω–æ–≤–ª–µ–Ω—ã:\n- –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞: {temperature}\n- –ú–æ–¥–µ–ª—å: {model}\n- –†–µ–∂–∏–º –∏—Å—Ç–æ—Ä–∏–∏: {history_view}"
    ).send()


@cl.on_chat_resume
async def on_chat_resume(thread: Dict[str, Any]):
    """Resume a previous chat session"""
    message_count = memory.get_message_count()
    await cl.Message(
        content=f"üìÇ –í–æ–∑–æ–±–Ω–æ–≤–ª—ë–Ω –¥–∏–∞–ª–æ–≥ —Å {message_count} —Å–æ–æ–±—â–µ–Ω–∏—è–º–∏."
    ).send()


@cl.on_chat_end
async def on_chat_end():
    """Handle chat session end"""
    await cl.Message(content="üëã –°–ø–∞—Å–∏–±–æ –∑–∞ –æ–±—â–µ–Ω–∏–µ! –î–æ —Å–≤–∏–¥–∞–Ω–∏—è!").send()


if __name__ == "__main__":
    # Run the Chainlit app
    cl.run()
