см. файл RESULTS.md

Запрос: "быстрая сортировка на python"

Модель: aliceai-llm
Токенов на запрос: 14, ответ: 848, итого: 862, время выполнения 8.97с
В ответе 2736 символов. Несколько вариантов алгоритма, оценка сложности, преимущества, недостатки, советы. Очень подробно.

Модель: yandexgpt-lite
Токенов на запрос: 15, ответ: 267, итого: 282, время выполнения 3.82с
В ответе 906 символов. Один вариант с примером использования.

Модель: llama3.2:1b (локально через Ollama)
Токенов на запрос: 33, ответ: 618, итого: 651, время выполнения 3.31с
В ответе 1820 символов. Сделала 5 вариантов но не сам алгоритм а использования встроенной функции sorted.

Модель: mistral-tiny (провайдер - Mistral)
Токенов на запрос: 13, ответ: 447, итого: 460, время выполнения 2.89с
В ответе 1133 символов. Один вариант + 2 абзаца описания.

Выводы.
Очевидно: 
    Чем больше и качественнее модель, тем более качественный ответ она дает. 
    Чем больше и качественнее модель, тем медленнее она работает и тем дороже получается миллион токенов. 
Неочевидно: 
    Слабая модель (llama3.2:1b) может сделать не совсем то что надо и потратить на это много токенов. 
    Слабая модель плохо работает с русским языком, возможно из-за этого тратит больше токенов, работая на русском. llama3.2:1b потратила на запрос в два раза больше токенов, чем более умные модели.